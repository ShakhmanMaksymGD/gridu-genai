# Synthetic Data Generation & Analysis Platform

A comprehensive AI-driven platform for generating realistic synthetic data from database schemas and querying it with natural language using Google's Gemini 2.0 Flash.

## Features

### Core Features (Completed)
- ğŸ“Š **DDL Schema Parsing**: Parse SQL DDL files and extract table structures, constraints, and relationships
- ğŸ¤– **AI-Powered Data Generation**: Use Gemini 2.0 Flash with function calling for realistic synthetic data
- ğŸ”„ **Data Modification**: Modify generated data through natural language instructions
- ğŸ’¾ **PostgreSQL Integration**: Store and manage data in PostgreSQL database
- ğŸ¯ **Modular UI**: Clean, maintainable Streamlit interface with component-based architecture
- ğŸ“Š **Observability**: Langfuse integration for monitoring and analytics
- ğŸ³ **Containerized**: Docker support for easy deployment
- ğŸ’¬ **Natural Language Querying**: Talk-to-your-data functionality with conversational AI interface
- ğŸ“ˆ **Data Visualization**: Auto-generated charts and plots from query results
- ğŸ”’ **Security Guardrails**: SQL injection protection and prompt injection detection
- ğŸ’¾ **Chat History**: Persistent conversation storage and management

### Planned Enhancements
- ğŸ” **Advanced Analytics**: Enhanced statistical analysis and insights
- ğŸ“Š **Custom Visualization Options**: More chart types and customization
- ğŸš€ **Performance Optimization**: Query caching and optimization

## Quick Start

### Prerequisites
- Docker and Docker Compose
- Google Cloud Project with Gemini API access
- Langfuse account (optional, for observability)

### Setup

1. **Clone and navigate to the project**:
   ```bash
   git clone <repository-url>
   cd ai-practice
   ```

2. **Set up environment variables**:
   ```bash
   cp .env.example .env
   # Edit .env with your actual values
   ```

3. **Required environment variables**:
   - `GEMINI_API_KEY`: Your Google Gemini API key
   - `GOOGLE_CLOUD_PROJECT`: Your GCP project ID
   - Optional: `LANGFUSE_SECRET_KEY`, `LANGFUSE_PUBLIC_KEY` for observability

4. **Start the application**:
   ```bash
   docker-compose up --build
   ```

5. **Access the application**:
   - Main App: http://localhost:8501
   - pgAdmin (optional): http://localhost:5050

### Manual Installation

If you prefer to run without Docker:

1. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

2. **Set up PostgreSQL**:
   - Install PostgreSQL locally
   - Create database: `synthetic_data_app`
   - Update connection settings in `.env`

3. **Run the application**:
   ```bash
   streamlit run app.py
   ```

## Usage

### 1. Upload DDL Schema
- Upload a `.sql`, `.txt`, or `.ddl` file containing CREATE TABLE statements
- Or use one of the provided sample schemas:
  - Company/Employee schema
  - Library Management schema
  - Restaurant schema

### 2. Configure Generation Parameters
- **Rows per table**: Number of rows to generate (1-10,000)
- **Temperature**: Controls randomness (0.0-1.0)
- **Instructions**: Provide specific guidance for data generation

### 3. Generate Data
- Click "Generate Data" to create synthetic data
- Preview generated tables
- Data is automatically stored in PostgreSQL

### 4. Query Your Data
- Navigate to the "ğŸ’¬ Talk to your data" tab
- Ask questions about your generated data in natural language
- Examples: "Show me the average salary by department", "Create a chart of employee ages"
- The AI will generate SQL queries, execute them safely, and create visualizations

### 5. Modify Data
- In the Data Generation tab, select any table to modify
- Provide natural language instructions
- Example: "Make all employees older than 25", "Increase salaries by 10%"

## Architecture

```
â”œâ”€â”€ app.py                          # Main Streamlit application (refactored)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ chat/                            # Natural language querying system
â”‚   â”‚   â”œâ”€â”€ chat_interface.py            # Main chat interface with AI and visualization
â”‚   â”‚   â”œâ”€â”€ chat_history.py              # Chat conversation persistence
â”‚   â”‚   â””â”€â”€ __init__.py                  # Package exports
â”‚   â”œâ”€â”€ data_generation/
â”‚   â”‚   â””â”€â”€ synthetic_data_generator.py  # Gemini-powered data generator
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â””â”€â”€ postgres_handler.py          # PostgreSQL operations
â”‚   â”œâ”€â”€ ui/                              # Modular UI components
â”‚   â”‚   â”œâ”€â”€ __init__.py                  # Package exports
â”‚   â”‚   â”œâ”€â”€ session_manager.py           # Session state management
â”‚   â”‚   â”œâ”€â”€ styles.py                    # CSS styling and UI utilities
â”‚   â”‚   â”œâ”€â”€ file_upload.py               # File upload handling
â”‚   â”‚   â”œâ”€â”€ data_generation.py           # Data generation UI and logic
â”‚   â”‚   â”œâ”€â”€ chat_ui.py                   # Chat interface UI components
â”‚   â”‚   â””â”€â”€ pages.py                     # Page components and navigation
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ ddl_parser.py                # DDL parsing logic
â”‚       â”œâ”€â”€ langfuse_observer.py         # Observability integration
â”‚       â””â”€â”€ session_utils.py             # Session utilities
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py                      # Configuration management
â”œâ”€â”€ samplers/                            # Sample DDL schemas
â”œâ”€â”€ data/                               # Generated data storage
â””â”€â”€ docker-compose.yml                 # Container orchestration
```

## Sample DDL Schemas

The project includes three sample schemas:

1. **Company/Employee**: Companies, departments, employees, projects, benefits, reviews
2. **Library Management**: Authors, publishers, books, branches, members, loans
3. **Restaurant**: Restaurants, customers, orders, menu items, staff

## Natural Language Querying

The "Talk to your data" feature provides a conversational AI interface for querying your generated data:

### Key Capabilities
- **Natural Language Processing**: Ask questions in plain English about your data
- **SQL Generation**: AI automatically converts your questions into safe SQL queries
- **Data Visualization**: Automatic chart generation (bar, line, scatter, histogram)
- **Security**: Built-in SQL injection and prompt injection protection
- **Context Awareness**: Maintains conversation history for follow-up questions

### Example Queries
- "Show me the average salary by department"
- "Which employees earn more than $75,000?"
- "Create a chart showing the age distribution"
- "How many orders were placed last month?"
- "What's the most popular menu item?"

### Security Features
- Only SELECT queries are allowed (no data modification)
- Pattern matching prevents dangerous SQL operations
- Prompt injection detection blocks malicious inputs
- Query validation before execution

## Configuration

Key configuration options in `config/settings.py`:

- `default_rows_per_table`: Default number of rows (1000)
- `default_temperature`: Default AI temperature (0.7)
- `max_retries`: Maximum retry attempts (3)
- Database connection settings
- Langfuse observability settings

## API Keys Setup

### Google Gemini API
1. Go to [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Create an API key
3. Set `GEMINI_API_KEY` in your `.env` file

### Langfuse (Optional)
1. Sign up at [Langfuse](https://langfuse.com)
2. Create a new project
3. Copy your public and secret keys
4. Set `LANGFUSE_PUBLIC_KEY` and `LANGFUSE_SECRET_KEY` in your `.env` file

## Observability

The application integrates with Langfuse for:
- LLM interaction monitoring
- Performance metrics
- Error tracking
- User action analytics
- Data generation session tracking
- Chat conversation analysis

## Development

### Running in Development Mode

```bash
# Set DEBUG=True in .env file
streamlit run app.py --server.runOnSave true
```

### Adding New Data Types

1. Update `DataType` enum in `ddl_parser.py`
2. Add conversion logic in `_convert_data_type()` method
3. Update data generation prompts if needed

### Extending UI

Add new components in the `src/ui/` directory and import them in `app.py`.

### Adding New Chat Features

1. Extend `ChatInterface` class in `src/chat/chat_interface.py`
2. Add function declarations for new AI capabilities
3. Update UI components in `src/ui/chat_ui.py`

## Troubleshooting

### Common Issues

1. **Database connection failed**:
   - Ensure PostgreSQL is running
   - Check connection settings in `.env`
   - Wait for database to fully start in Docker

2. **Gemini API errors**:
   - Verify your API key is correct
   - Check your Google Cloud project has Gemini API enabled
   - Ensure you have sufficient quota

3. **Data generation slow or failing**:
   - Reduce the number of rows per table
   - Simplify your instructions
   - Check Langfuse logs for detailed error information

4. **Chat/Query issues**:
   - Ensure you have generated data before using the chat feature
   - Check that your natural language queries are clear and specific
   - Verify database connectivity if queries fail

5. **Docker issues**:
   - Ensure Docker has sufficient memory allocated
   - Check container logs: `docker-compose logs app`

### Logs

- Application logs: Check Docker logs or console output
- Database logs: `docker-compose logs postgres`
- Langfuse dashboard: Monitor LLM interactions and performance